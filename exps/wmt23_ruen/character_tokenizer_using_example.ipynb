{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b4803c-2e9b-4b2d-8900-a569b060ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, sys; sys.path.append(  # noqa: E401, E702\n",
    "    (pathlib.Path(\".\").resolve().parent.parent / \".\").as_posix()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1d20a2-ad5e-41b2-8ec6-c14c3f2ca107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.types.tokenizers import CharacterTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4425cb37-d72c-4b0e-a585-6640a268caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharacterTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fdb456-d1e5-4b1c-9f35-61c072078b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Class `CharacterTokenizer` may have only 1 instance!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unallowed_second_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mCharacterTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_github/dl_dev/lib/types/commons.py:14\u001b[0m, in \u001b[0;36mBaseStrictSingleton.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` may have only 1 instance!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instance: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseStrictSingleton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Class `CharacterTokenizer` may have only 1 instance!"
     ]
    }
   ],
   "source": [
    "unallowed_second_tokenizer = CharacterTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abeb9ec1-f1b0-492e-b1f2-b13ac375d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.load(\n",
    "    pathlib.Path(\"/home/david_tyuman/my_github/dl_dev/character_tokenizer_dict.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4612312-1788-4338-833e-baea749cd146",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tokenizer's already fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msome_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_github/dl_dev/lib/types/tokenizers/base.py:36\u001b[0m, in \u001b[0;36mBaseTokenizer.fit\u001b[0;34m(self, path, limit)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: pathlib\u001b[38;5;241m.\u001b[39mPosixPath, limit: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_available_to_be_fitted:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms already fitted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl(path, limit)\n",
      "\u001b[0;31mValueError\u001b[0m: Tokenizer's already fitted"
     ]
    }
   ],
   "source": [
    "tokenizer.fit(\"some_path\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68434803-8572-4fe4-94ef-473d06d97a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 1, 20, 20, 6, 138]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"hello!\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ab2631-93eb-41d3-a8af-d8cf860aed7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c02592-9b60-4511-a60e-4b3868b6e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"asds1201n)ыфвфь!@)B(N))мг0тцс18И(Н.,;И1234567890-+_)(*&^%$#@1234567890_)(;.,:%пиро  N0710212js   'ad\"\n",
    "s == tokenizer.decode(tokenizer.encode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5004365c-7990-4e9d-9a78-c8d649688ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157, 157, 157]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"���\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a90535c6-0cc9-4095-b7e8-a65a6c776c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'�'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = tokenizer.decode([987654321123456789])\n",
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd772d77-939c-43b6-9c66-a8243b5f9ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f2ad20-c04c-4cd6-a054-d35d98f3c42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59, -1, -1, 106]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"A△▽W\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a63315b6-0285-414a-817d-bcf2ff841b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 means unknown token, a token that hasn't been observed while tokenizer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3869eb0d-7b63-4e6f-a989-4dfe226c1acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A��W'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75895b2d-d3e9-4655-88d9-878ef987fe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 35, 17, 14]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"⊲⊳ ⏏ ⌫ ⌧ ⌦ ⍓ ⍌ ⍃ывs\"\n",
    "tokens = tokenizer.encode(s)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc48b6d2-d030-4ff2-887d-782e55cb6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (tokenizer.decode(tokenizer.encode(s)) == s) is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14db849f-d426-4050-b241-79eca53e7d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18,   9, 138,   0,  43,   9,   3,  22,  18, 138], dtype=int16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(tokenizer.encode(\"hi! bitch!\"), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b86f16-509a-4e66-ab61-8773ad6b0b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff16b07b-8ef4-459d-b0b5-1847beaf7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f_ds = h5py.File(\n",
    "    \"/var/lib/storage/data/benchmarks/machine_translation/wmt/wmt23_ruen/wrangled/char100000tokenized_val_0.h5\",\n",
    "    \"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368af019-6230-474b-b8e0-17a2af73b602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(0, len(f_ds[\"input\"]) - 1)\n",
    "inp = f_ds[\"input\"][i]\n",
    "oup = f_ds[\"output\"][i]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71950b4-0ba7-4f8e-9709-283b3895fb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107,   4,   2,  16,  37,   5,  42,   0, 117,   4,  23,   2,  16,\n",
       "         2,  17,   0,  16,   8,  15,  15,  24,   8,  38,   8,  19,   0,\n",
       "        54, 101,  38,  17,   4,  15,  13,   5,  34,  25,  54,  28,   0,\n",
       "        45,  13,   2,   0,   5,  23,   4,  34,   0,  15,   2,  38,  23,\n",
       "         8,  13,  40,   0,  26,   2,  23,   2,  39,  11,  35,  42,   0,\n",
       "        16,   4,  42,  13,   5,  11,  37,   0,  17,   2,  38,  11,   5,\n",
       "        24,  19,   8,   0,  26,   2,  15,  19,   4,   0,   5,  38,  31,\n",
       "        45,   4,  11,   5,  34,   0,   2,  26,  35,  13,   8,   0,  84,\n",
       "         8,  49,   5,   2,  11,   8,  19,  40,  11,   2,  37,   2,   0,\n",
       "         2,  39, 116,   4,  23,   5,  11,   4,  11,   5,  34,   0,   5,\n",
       "        38,  35,  15,  24,   8,  13,   4,  19,   4,  42,   0,   5,   0,\n",
       "        26,  16,   2,   4,  24,  13,   5,  16,   2,  17,  58,   5,  24,\n",
       "         2,  17,   0,  68,  84,  78,  73,  90, 101, 121,  67,  28,   0,\n",
       "        24,   2,  13,   2,  16,   2,   4,   0,  31,  48,   4,   0,  11,\n",
       "         8,  45,   8,  19,   2,   0,  16,   8,  39,   2,  13,  31,   0,\n",
       "        26,   2,   0,  15,   2,  38,  23,   8,  11,   5,  51,   0,  15,\n",
       "        26,   4,  49,   5,   8,  19,   5,  38,   5,  16,   2,  17,   8,\n",
       "        11,  11,   2,  37,   2,   0,  16,   4,   4,  15,  13,  16,   8,\n",
       "         0,   5,  11,  11,   2,  17,   8,  49,   5,   2,  11,  11,  35,\n",
       "        47,   0,  15,  13,  16,   2,   5,  13,   4,  19,  40,  11,  35,\n",
       "        47,   0,  25,   8,  13,   4,  16,   5,   8,  19,   2,  17,   0,\n",
       "         5,   0,  16,   4,   4,  15,  13,  16,   8,   0,   5,  25,  26,\n",
       "         2,  16,  13,   2,  38,   8,  25,   4,  58,   4,  11,   5,  34,\n",
       "         0,  15,  13,  16,   2,   5,  13,   4,  19,  40,  11,  35,  47,\n",
       "         0,  25,   8,  13,   4,  16,   5,   8,  19,   2,  17,  33],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84f36b18-bf1a-48d4-9dbf-417100201976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96,   1,   6,  12,  36,   1,   0,  95,   1,  21,   6,  12,   6,\n",
       "        46,   0,   3,   6,  20,  21,   0,  54,  62,  99,  46,   1,  14,\n",
       "         3,   9,   7,  54,   0,   3,  18,   7,   3,   0,   3,  18,   1,\n",
       "         0,   9,  21,   1,   7,   0,   3,   6,   0,  22,  12,   1,   7,\n",
       "         3,   1,   0,  14,  27,  22,  18,   0,   7,   0,  12,   7,   3,\n",
       "         9,  10,  36,   0,   7,  12,   6,  14,   1,   0,   7,  30,   3,\n",
       "         1,  12,   0,   3,  18,   1,   0,  14,   3,  27,  21,  41,   0,\n",
       "         6,  30,   0,   3,  18,   1,   0,   1,  81,  32,   1,  12,   9,\n",
       "         1,  10,  22,   1,   0,   6,  30,   0,   3,  18,   1,   0,  83,\n",
       "         7,   3,   9,   6,  10,   7,  20,   0,  59,  14,  14,   6,  22,\n",
       "         9,   7,   3,   9,   6,  10,   0,   6,  30,   0,  32,  12,   6,\n",
       "        14,  32,   1,  22,   3,   6,  12,  14,   0,   7,  10,  21,   0,\n",
       "        21,   1,  14,   9,  36,  10,   1,  12,  14,   0,  68,  83,  98,\n",
       "        74,  70,  62, 134,  67,  28,   0,  44,  18,   9,  22,  18,   0,\n",
       "        18,   7,  14,   0,   7,  20,  12,   1,   7,  21,  41,   0,  43,\n",
       "         1,  36,  27,  10,   0,  44,   6,  12,  55,   0,   6,  10,   0,\n",
       "         3,  18,   1,   0,  22,  12,   1,   7,   3,   9,   6,  10,   0,\n",
       "         6,  30,   0,   7,   0,  21,   1,  21,   9,  22,   7,   3,   1,\n",
       "        21,   0,   9,  10,  46,   1,  10,   3,   6,  12,  41,   0,   6,\n",
       "        30,   0,   9,  10,  10,   6,  46,   7,   3,   9,  46,   1,   0,\n",
       "        43,  27,   9,  20,  21,   9,  10,  36,   0,  29,   7,   3,   1,\n",
       "        12,   9,   7,  20,  14,   0,   7,  10,  21,   0,   7,   0,  12,\n",
       "         1,  36,   9,  14,   3,   1,  12,   0,   6,  30,   0,   9,  29,\n",
       "        32,   6,  12,   3,   0,  12,   1,  32,  20,   7,  22,   1,  29,\n",
       "         1,  10,   3,   0,   6,  30,   0,  43,  27,   9,  20,  21,   9,\n",
       "        10,  36,   0,  29,   7,   3,   1,  12,   9,   7,  20,  14,  33],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522fc741-78d2-432c-b3ad-0f25bfb6e40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Георгий Федоров рассказал \"Известиям\", что идея создать подобный рейтинг возникла после изучения опыта Национального объединения изыскателей и проектировщиков (НОПРИЗ), которое уже начало работу по созданию специализированного реестра инновационных строительных материалов и реестра импортозамещения строительных материалов.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41152be8-ffd6-4d3a-ad0c-96ef6cb8839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George Fedorov told \"Izvestia\" that the idea to create such a rating arose after the study of the experience of the National Association of prospectors and designers (NOPRIZ), which has already begun work on the creation of a dedicated inventory of innovative building materials and a register of import replacement of building materials.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(oup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "108ccdc3-1719-4f90-9834-dad86260f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer.encode(tokenizer.decode(inp)) == inp.tolist()\n",
    "assert tokenizer.encode(tokenizer.decode(oup)) == oup.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15f8db-f88a-4c7e-bed9-3a9bd63fafa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72a38a65-3938-4305-a6c6-a3772a566e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(f_ds[\"input\"]) - 1)\n",
    "inp = f_ds[\"input\"][i]\n",
    "oup = f_ds[\"output\"][i]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b26765a5-e01b-4263-9e17-82144451130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73,  2, 71, 13,  2, 25, 31,  0, 15, 26,  4, 49,  5,  8, 19,  5, 15,\n",
       "       13, 35,  0,  5, 15, 24,  8, 19,  5,  0, 15, 26,  2, 15,  2, 39, 35,\n",
       "       28,  0, 24,  8, 24,  0, 39, 35, 15, 13, 16,  2,  0, 17,  2, 15, 15,\n",
       "       13,  8, 11,  2, 17,  5, 13, 40,  0, 24,  2, 48, 31,  0,  5,  0, 11,\n",
       "        4,  0, 23,  2, 26, 31, 15, 13,  5, 13, 40,  0, 16, 31, 39, 49,  4,\n",
       "       17,  8, 11,  5, 34, 33], dtype=int16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d729fe4-8adc-4c5a-a4ef-957ca47d2559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 18,  1, 12,  1, 30,  6, 12,  1, 28,  0,  3, 18,  1,  0, 14, 32,\n",
       "        1, 22,  9,  7, 20,  9, 14,  3, 14,  0, 44,  1, 12,  1,  0, 20,  6,\n",
       "        6, 55,  9, 10, 36,  0, 30,  6, 12,  0, 44,  7, 41, 14,  0,  3,  6,\n",
       "        0, 97, 27,  9, 22, 55, 20, 41,  0, 12,  1, 14,  3,  6, 12,  1,  0,\n",
       "        3, 18,  1,  0, 14, 55,  9, 10,  0,  7, 10, 21,  0,  7, 46,  6,  9,\n",
       "       21,  0, 22, 18,  6, 32, 32,  9, 10, 36, 33], dtype=int16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0cc9ade-5af3-48d0-abdc-d3ac392bb486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Поэтому специалисты искали способы, как быстро восстановить кожу и не допустить рубцевания.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f8ebcc-3662-4e10-8157-41e91e9c6583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Therefore, the specialists were looking for ways to quickly restore the skin and avoid chopping.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(oup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f3f8fe6-4b19-4382-a4dd-af48ba093841",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer.encode(tokenizer.decode(inp)) == inp.tolist()\n",
    "assert tokenizer.encode(tokenizer.decode(oup)) == oup.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0c36f72-eae7-4ee7-add4-00c0314ab623",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
